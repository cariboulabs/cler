<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Learn CLER with real examples: control systems, cyclic graphs, performance optimization. From basic blocks to advanced embedded DSP applications.">
    <meta name="keywords" content="CLER tutorial, DSP examples, embedded programming, C++ flowgraph, control systems, real-time processing">
    <title>Learn CLER - Documentation</title>
    <link rel="stylesheet" href="styles/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css">
    <style>
        /* Fix for scroll position when clicking navigation links */
        section[id] {
            scroll-margin-top: 80px; /* Adjust based on your nav height */
        }
    </style>
</head>
<body>
    <nav class="nav">
        <div class="nav-brand">
            <img src="cler-logo.jpeg" alt="CLER" class="logo">
        </div>
        <div class="nav-tabs">
            <a href="index.html" class="nav-tab">Home</a>
            <a href="learn.html" class="nav-tab active">Learn</a>
            <a href="blog.html" class="nav-tab">Blog</a>
        </div>
        <div class="nav-links">
            <a href="https://github.com/cariboulabs/cler" class="github-link" target="_blank">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                    <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                </svg>
            </a>
        </div>
    </nav>

    <main class="learn-page">
        <div class="container">
            <div class="sidebar">
                <button class="nav-toggle mobile-only" aria-label="Toggle navigation" aria-expanded="false" aria-controls="learnNav">☰</button>
                <nav class="learn-nav" id="learnNav">
                    <h3>Contents</h3>
                    <ul>
                        <li><a href="#understanding">Understanding CLER</a></li>
                        <li><a href="#core-concepts">Core Concepts</a></li>
                        <li><a href="#execution-models">Execution Models</a></li>
                        <li><a href="#platform-support">Platform Support</a></li>
                        <li><a href="#control-system">Control System Example</a></li>
                        <li><a href="#performance-example">Performance Considerations</a></li>
                        <li><a href="#scheduler-types">Scheduler Types & Optimization</a></li>
                        <li><a href="#buffer-patterns">Buffer Access Patterns</a></li>
                        <li><a href="#architecture">Architecture Deep Dive</a></li>
                    </ul>
                </nav>
            </div>

            <div class="content">
                <h1>Learn CLER</h1>
                <p class="intro">CLER is designed around simplicity: Blocks are just structs with methods, Channels are type-safe queues, and the framework compiles away to almost nothing.</p>

                <section id="understanding">
                    <h2>Understanding CLER</h2>
                    <p><strong>Real Examples, Real Code</strong></p>
                    <p>Learning DSP frameworks is best done by seeing working code in action. The examples below come directly from our desktop_examples directory — they're not toy code, but real applications demonstrating CLER's core capabilities.</p>
                    
                    <p><strong>Platform Support</strong></p>
                    <p>CLER supports both desktop and embedded platforms. Desktop examples use standard threads, while embedded frameworks include bare-metal, Zephyr, FreeRTOS, and ThreadX implementations.</p>
                </section>

                <section id="core-concepts">
                    <h2>Core Concepts</h2>
                    
                    <h3>Blocks Are Just Structs</h3>
                    <p>Every CLER block is a C++ struct with a <code>procedure()</code> method. Simple inheritance from BlockBase with minimal virtual functions only for interface:</p>
                    
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">struct GainBlock : public cler::BlockBase {
    float gain;
    
    GainBlock(const char* name, float gain_value) 
        : BlockBase(name), gain(gain_value) {}
    
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(
        cler::ChannelBase&lt;float&gt;* in,
        cler::ChannelBase&lt;float&gt;* out) {
        
        size_t transferable = std::min(in->size(), out->space());
        for (size_t i = 0; i < transferable; ++i) {
            float value;
            in->pop(value);
            out->push(value * gain);
        }
        return cler::Empty{};
    }
};</code></pre>
                    </div>
                    <p class="design-note"><strong>Design Rationale:</strong> Minimal virtual functions (only for interface), very little runtime type erasure, minimal hidden costs. What you write is mostly what gets compiled.</p>

                    <h3>Multiple Input/Output Blocks</h3>
                    <p>Blocks can have any number of inputs and outputs. Here's an adder that takes 2 inputs:</p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">struct AdderBlock : public cler::BlockBase {
    cler::Channel&lt;float&gt; in0;   // First input channel (owned by block)
    cler::Channel&lt;double&gt; in1;  // Second input (different type!)
    
    AdderBlock(const char* name) : BlockBase(name), in0(512), in1(512) {}
    
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(
        cler::ChannelBase&lt;float&gt;* out) {
        
        size_t transferable = std::min({in0.size(), in1.size(), out->space()});
        for (size_t i = 0; i < transferable; ++i) {
            float value0;
            double value1;
            in0.pop(value0);
            in1.pop(value1);
            out->push(value0 + static_cast&lt;float&gt;(value1));
        }
        return cler::Empty{};
    }
};</code></pre>
                    </div>
                    <p class="key-point"><strong>Key Design:</strong> Input channels are owned by the block, output channels are passed as parameters. This prevents one-to-many connection issues.</p>

                    <h3>Type-Agnostic Channels</h3>
                    <p>Channels work with any type — not just numbers:</p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">// Custom packet type
struct Packet {
    uint32_t id;
    std::vector&lt;uint8_t&gt; data;
};

// Channel that carries packets
cler::Channel&lt;Packet&gt; packet_channel(64);

// Block that processes packets
struct PacketProcessor : public cler::BlockBase {
    cler::Channel&lt;Packet&gt; in;  // Input channel owned by block
    
    PacketProcessor(const char* name) : BlockBase(name), in(64) {}
    
    template&lt;typename... OChannels&gt;
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(OChannels*... outs) {
        Packet packet;
        while (in.pop(packet)) {
            // Process packet...
            packet.id += 1000;  // Example processing
            // Push to all outputs using fold expression
            ((outs->push(packet)), ...);
        }
        return cler::Empty{};
    }
};</code></pre>
                    </div>
                    <p class="key-point"><strong>Flexibility:</strong> You're not limited to primitive types. Pass complex data structures, protocol packets, or custom objects between blocks.</p>
                </section>

                <section id="execution-models">
                    <h2>Two Execution Models</h2>
                    <p>Different applications need different trade-offs. Flowgraph mode is convenient and handles threading for you. Streamlined mode gives you maximum control for embedded systems or when you need every microsecond.</p>
                    
                    <h3>Flowgraph Mode</h3>
                    <p>Each block runs in its own thread, framework manages everything:</p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">// Desktop version
auto flowgraph = cler::make_desktop_flowgraph(
    cler::BlockRunner(&amp;source, &amp;adder.in[0], &amp;adder.in[1]),  // multiple outputs
    cler::BlockRunner(&amp;adder, &amp;gain.in),                     // single output
    cler::BlockRunner(&amp;gain, &amp;sink.in),
    cler::BlockRunner(&amp;sink)                                  // no outputs (sink)
);

// Configure scheduler and performance options
cler::FlowGraphConfig config;
config.scheduler = cler::SchedulerType::ThreadPerBlock;  // Or FixedThreadPool (recommended)
// config.adaptive_sleep = true;  // Optional: for sparse/intermittent data only
flowgraph.run(config);

// Embedded version (FreeRTOS example)
#include "task_policies/cler_freertos_tpolicy.hpp"
auto flowgraph = cler::FlowGraph&lt;cler::FreeRTOSTaskPolicy,
    decltype(cler::BlockRunner(&amp;source, &amp;adder.in[0], &amp;adder.in[1])),
    decltype(cler::BlockRunner(&amp;adder, &amp;gain.in)),
    decltype(cler::BlockRunner(&amp;gain, &amp;sink.in)),
    decltype(cler::BlockRunner(&amp;sink))
&gt;(
    cler::BlockRunner(&amp;source, &amp;adder.in[0], &amp;adder.in[1]),
    cler::BlockRunner(&amp;adder, &amp;gain.in),
    cler::BlockRunner(&amp;gain, &amp;sink.in),
    cler::BlockRunner(&amp;sink)
);

flowgraph.run(config);  // Same config works on all platforms</code></pre>
                    </div>
                    <p class="key-point"><strong>BlockRunner Syntax:</strong> First argument is the block, remaining arguments are its outputs (passed to procedure() as parameters). Same syntax works across all platforms.</p>

                    <h3>Streamlined Mode</h3>
                    <p>You control the loop, manual scheduling (from streamlined.cpp):</p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">while (true) {
    source.procedure(&amp;adder.in[0], &amp;adder.in[1]);  // multiple outputs
    adder.procedure(&amp;gain.in);                      // single output
    gain.procedure(&amp;sink.in);
    sink.procedure();                                // no outputs
}</code></pre>
                    </div>
                    <p class="design-note"><strong>Use Cases:</strong> When blocks are simple, you avoid thread overhead. Perfect for embedded systems or when you need deterministic timing.</p>
                </section>

                <section id="platform-support">
                    <h2>Platform Support & Task Policies</h2>
                    <p>CLER supports multiple platforms through its task policy abstraction. Different platforms require different threading models, but the same block code works everywhere.</p>
                    
                    <h3>Desktop Development</h3>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">#include "cler.hpp"
#include "task_policies/cler_desktop_tpolicy.hpp"

int main() {
    // Create blocks...
    SourceCWBlock&lt;float&gt; source("Source", 1.0f, 10.0f, 1000);
    GainBlock&lt;float&gt; gain("Gain", 2.0f);
    
    // Desktop flowgraph uses std::thread
    auto flowgraph = cler::make_desktop_flowgraph(
        cler::BlockRunner(&amp;source, &amp;gain.in),
        cler::BlockRunner(&amp;gain, &amp;sink.in),
        cler::BlockRunner(&amp;sink)
    );
    
    // Configure scheduler for optimal performance
    cler::FlowGraphConfig config;
    config.scheduler = cler::SchedulerType::ThreadPerBlock;  // Good default
    // config.adaptive_sleep = true;  // Optional: reduce CPU when idle
    flowgraph.run(config);
    return 0;
}</code></pre>
                    </div>
                    
                    <h3>Embedded Systems</h3>
                    
                    <h4>FreeRTOS</h4>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">#include "cler.hpp"
#include "task_policies/cler_freertos_tpolicy.hpp"

int main() {
    // Same blocks work on any platform
    SourceCWBlock&lt;float&gt; source("Source", 1.0f, 10.0f, 1000);
    GainBlock&lt;float&gt; gain("Gain", 2.0f);
    
    // FreeRTOS flowgraph uses xTaskCreate
    auto flowgraph = cler::FlowGraph&lt;cler::FreeRTOSTaskPolicy,
        decltype(cler::BlockRunner(&amp;source, &amp;gain.in)),
        decltype(cler::BlockRunner(&amp;gain, &amp;sink.in)),
        decltype(cler::BlockRunner(&amp;sink))
    &gt;(
        cler::BlockRunner(&amp;source, &amp;gain.in),
        cler::BlockRunner(&amp;gain, &amp;sink.in),
        cler::BlockRunner(&amp;sink)
    );
    
    flowgraph.run();
    vTaskStartScheduler();  // FreeRTOS scheduler
    return 0;
}</code></pre>
                    </div>
                    
                    <h4>Bare Metal (No Threading)</h4>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">#include "cler.hpp"
// No task policy needed for bare metal

int main() {
    // Stack-allocated channels for deterministic memory
    struct SimpleBlock : public cler::BlockBase {
        cler::Channel&lt;float, 64&gt; in;  // Fixed size, no heap allocation
        
        SimpleBlock(const char* name) : BlockBase(name) {}
        
        template&lt;typename... OChannels&gt;
        cler::Result&lt;cler::Empty, cler::Error&gt; procedure(OChannels*... outs) {
            // Minimal processing for embedded constraints
            float sample;
            while (in.pop(sample)) {
                ((outs->push(sample * 2.0f)), ...);
            }
            return cler::Empty{};
        }
    };
    
    SimpleBlock block1("Block1"), block2("Block2");
    
    // Streamlined mode only for bare metal
    while (true) {
        block1.procedure(&amp;block2.in);
        block2.procedure();  // No outputs
        // Hardware-specific timing control
    }
}</code></pre>
                    </div>
                    
                    <div class="key-point">
                        <strong>Platform Abstraction:</strong> The same block code works on desktop (std::thread), FreeRTOS (xTaskCreate), ThreadX (tx_thread_create), Zephyr (k_thread_create), or bare metal (no threading). Only the task policy changes.
                    </div>
                </section>

                <section id="control-system">
                    <h2>Cyclic Graphs - Control System Example</h2>
                    <p>This demonstrates CLER's support for cyclic graphs — the controller's output feeds the plant, and the plant's output feeds back to the controller, creating a closed feedback loop. This isn't just signal processing — it's a complete interactive simulation with real-time GUI controls.</p>
                    
                    <h3>The Plant Block</h3>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">struct PlantBlock : public cler::BlockBase {
    cler::Channel&lt;float&gt; force_in;
    
    PlantBlock(const char* name) : BlockBase(name), force_in(cler::DEFAULT_BUFFER_SIZE) {
        force_in.push(0.0f); // CRITICAL: Initial force for cyclic graph
    }
    
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(
        cler::ChannelBase&lt;float&gt;* measured_position_out) {
        
        float force;
        force_in.pop(force);
        
        // Mass-spring-damper physics simulation
        float acceleration = (force - K * _x - C * _v) / M;
        _v += acceleration * DT;
        _x += _v * DT + 0.5f * acceleration * DT * DT;
        
        measured_position_out->push(_x);
        return cler::Empty{};
    }
    
private:
    float _x = 0.0, _v = 0.0;  // Position and velocity state
};</code></pre>
                    </div>
                    <p class="key-point"><strong>Critical Detail:</strong> The plant block maintains internal state and connects to the controller in a feedback loop. The <code>force_in.push(0.0f)</code> is crucial — cyclic graphs need initial conditions or they'll deadlock on startup.</p>
                    
                    <h3>Interactive PID Controller with Thread-Safe GUI</h3>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">struct ControllerBlock : public cler::BlockBase {
    cler::Channel&lt;float&gt; measured_position_in;
    
    // Thread-safe parameters modified by GUI
    std::atomic&lt;float&gt; _kp{2.0f}, _ki{1.0f}, _kd{1.0f};
    std::atomic&lt;float&gt; _target{10.0f};
    std::atomic&lt;bool&gt;  _feed_forward{false};
    
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(
        cler::ChannelBase&lt;float&gt;* force_out) {
        
        float measured_position;
        measured_position_in.pop(measured_position);
        
        // Read parameters atomically (modified by GUI thread)
        float target = _target.load(std::memory_order_relaxed);
        float kp = _kp.load(std::memory_order_relaxed);
        
        float error = target - measured_position;
        float derivative = (error - _error_prev) / DT;
        _integral += error * DT;
        
        float force = kp * error + _ki.load() * _integral + _kd.load() * derivative;
        
        // Optional feed-forward control
        if (_feed_forward.load()) {
            force += K * target;  // Compensation for spring constant
        }
        
        force_out->push(force);
        _error_prev = error;
        return cler::Empty{};
    }
    
private:
    float _error_prev = 0.0, _integral = 0.0;
};</code></pre>
                    </div>
                    <p class="key-point"><strong>Thread Safety:</strong> The GUI thread modifies PID parameters while the control loop runs at 100Hz. Atomic variables ensure thread-safe updates without locks, maintaining real-time performance. The controller remains responsive even while parameters change.</p>
                    
                    <h3>The Cyclic Flowgraph</h3>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">auto flowgraph = cler::make_desktop_flowgraph(
    cler::BlockRunner(&controller, &throttle.in),
    cler::BlockRunner(&throttle, &plant.force_in),          // Controller → Plant
    cler::BlockRunner(&plant, &fanout.in),
    cler::BlockRunner(&fanout, &plot.in[0], &controller.measured_position_in)  // Plant → Controller (feedback)
);</code></pre>
                    </div>
                    <p><strong>BlockRunner Syntax:</strong> First argument is the block to run, remaining arguments are the outputs (channels passed to the block's procedure() method).</p>
                    <p class="design-note"><strong>Feedback Loop:</strong> Notice how the data flows Controller → Plant → Fanout → back to Controller, creating a complete feedback loop. The initial force value in the plant prevents deadlock at startup.</p>
                </section>

                <section id="performance-example">
                    <h2>Performance Considerations</h2>
                    <p>Choosing between flowgraph and streamlined modes depends on the computational weight of your blocks versus the overhead of orchestration.</p>
                    
                    <h3>When Streamlined Mode Wins</h3>
                    <p>If your blocks do minimal work per sample, the thread synchronization overhead in flowgraph mode can dominate. Consider this anti-pattern:</p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">// Anti-pattern: Simple gain block in flowgraph mode
struct GainBlock : public cler::BlockBase {
    cler::Channel&lt;float&gt; in;  // Input channel owned by block
    float gain;
    
    GainBlock(const char* name, float gain_value) 
        : BlockBase(name), in(512), gain(gain_value) {}
    
    template&lt;typename... OChannels&gt;
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(OChannels*... outs) {
        // Just multiplying by a constant - very little work!
        float value;
        while (in.pop(value)) {
            // Push to all outputs using fold expression
            ((outs->push(value * gain)), ...);
        }
        return cler::Empty{};
    }
};</code></pre>
                    </div>
                    <p class="design-note"><strong>The Problem:</strong> Each sample requires thread synchronization (pushing/popping from channels). The overhead of synchronization far exceeds the actual computation (one multiplication).</p>
                    
                    <h3>Better Approaches</h3>
                    <p><strong>Option 1: Combine lightweight operations into heavier blocks</strong></p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">// Better: Combine multiple operations
struct ProcessingBlock : public cler::BlockBase {
    cler::Channel&lt;float&gt; in;  // Input channel owned by block
    float gain;
    float offset;
    
    ProcessingBlock(const char* name, float gain_value, float offset_value)
        : BlockBase(name), in(512), gain(gain_value), offset(offset_value) {}
    
    template&lt;typename... OChannels&gt;
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(OChannels*... outs) {
        float buffer[256];
        size_t count = in.readN(buffer, 256);
        
        // Process in batches - amortizes synchronization cost
        for (size_t i = 0; i < count; ++i) {
            buffer[i] = buffer[i] * gain + offset;
            // Could add filtering, decimation, etc. here
        }
        
        // Write to all outputs using fold expression
        ((outs->writeN(buffer, count)), ...);
        return cler::Empty{};
    }
};</code></pre>
                    </div>
                    
                    <p><strong>Option 2: Use streamlined mode for simple chains</strong></p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">// Streamlined mode - no thread overhead
while (running) {
    source.procedure(&amp;gain.in);
    gain.procedure(&amp;offset.in);
    offset.procedure(&amp;sink.in);
    sink.procedure();
}</code></pre>
                    </div>
                    
                    <h3>Stack-Allocated Channels</h3>
                    <p>For embedded systems or when you know the exact buffer size needed:</p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">struct FilterBlock : public cler::BlockBase {
    // Stack-allocated channel - no heap allocation!
    cler::Channel&lt;float, 1024&gt; in;  // Template parameter sets size
    
    FilterBlock(const char* name) : BlockBase(name) {}
    
    template&lt;typename... OChannels&gt;
    cler::Result&lt;cler::Empty, cler::Error&gt; procedure(OChannels*... outs) {
        // Process data...
        // Push to all outputs using fold expression when ready
        return cler::Empty{};
    }
};</code></pre>
                    </div>
                    <p class="key-point"><strong>Benefits:</strong> No dynamic allocation, better cache locality, deterministic memory usage — critical for real-time embedded systems.</p>
                </section>

                <section id="scheduler-types">
                    <h2>Scheduler Types & Performance Optimization</h2>
                    <p>CLER provides two highly optimized schedulers designed for different workload characteristics. Choosing the right scheduler can significantly improve throughput and reduce CPU usage.</p>
                    
                    <h3>ThreadPerBlock (Default)</h3>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">cler::FlowGraphConfig config;
config.scheduler = cler::SchedulerType::ThreadPerBlock;  // Default
// config.adaptive_sleep = true;  // Only for sparse/intermittent data
flowgraph.run(config);</code></pre>
                    </div>
                    <p><strong>Best for:</strong> Small flowgraphs, debugging, uniform workloads</p>
                    <p><strong>Characteristics:</strong> One dedicated thread per block</p>
                    <p class="design-note"><strong>Trade-offs:</strong> Simple and predictable, but thread overhead grows with block count. Good starting point for most applications.</p>
                    
                    <h3>FixedThreadPool (Cache-Optimized)</h3>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">cler::FlowGraphConfig config;
config.scheduler = cler::SchedulerType::FixedThreadPool;  // Recommended
config.num_workers = 4;  // Number of worker threads (minimum 2, adjust for your CPU)
// config.adaptive_sleep = true;  // Optional: only for sparse data
flowgraph.run(config);</code></pre>
                    </div>
                    <p><strong>Best for:</strong> Most desktop applications, uniform workloads, performance-critical scenarios</p>
                    <p><strong>Characteristics:</strong> Cache-aligned worker threads with platform-aware memory layout</p>
                    <p class="key-point"><strong>Benefits:</strong> +30-40% performance improvement, automatic cache line detection for x86/ARM/RISC-V, lower thread overhead than ThreadPerBlock.</p>
                    
                    <h3>Adaptive Sleep Configuration</h3>
                    <p><strong>⚠️ Warning:</strong> Adaptive sleep reduces CPU usage but can significantly impact throughput. Only use for sparse/intermittent data sources like sensors or network packets with gaps.</p>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">// Adaptive sleep works with both scheduler types - USE CAREFULLY
// Can significantly reduce throughput, only use for sparse/intermittent data
config.adaptive_sleep = true;  // CAUTION: reduces CPU usage but may impact throughput
config.adaptive_sleep_multiplier = 1.5;       // How aggressively to increase sleep
config.adaptive_sleep_max_us = 5000.0;        // Maximum sleep time (microseconds)
config.adaptive_sleep_fail_threshold = 10;    // Start sleeping after N failures

// For very sparse data (sensors, network packets)
config.adaptive_sleep_multiplier = 2.0;       // Aggressive backoff
config.adaptive_sleep_max_us = 10000.0;       // Up to 10ms sleep
config.adaptive_sleep_fail_threshold = 5;     // Sleep after 5 failures</code></pre>
                    </div>
                    <p class="design-note"><strong>Use Cases:</strong> Sensor data, network packets, user input processing. Can achieve >90% CPU reduction during idle periods while maintaining low latency when data arrives.</p>
                </section>

                <section id="buffer-patterns">
                    <h2>Three Buffer Access Patterns</h2>
                    <p>Different algorithms need different memory access patterns. CLER supports them all efficiently, from simple single-sample processing to zero-copy bulk operations.</p>
                    
                    <div class="pattern-comparison">
                        <div class="pattern">
                            <h3>1. Push/Pop (Simplest)</h3>
                            <div class="code-block">
                                <pre><code class="language-cpp line-numbers">float sample;
in->pop(sample);
out->push(sample * gain);</code></pre>
                            </div>
                            <p class="pattern-note slow">⚠️ <strong>Slowest</strong> - Use only for simple, low-rate processing</p>
                        </div>
                        
                        <div class="pattern">
                            <h3>2. Read/Write (Recommended)</h3>
                            <div class="code-block">
                                <pre><code class="language-cpp line-numbers">float buffer[256];
size_t count = in->readN(buffer, 256);
// Process entire buffer...
for (size_t i = 0; i < count; ++i) {
    buffer[i] *= gain;
}
out->writeN(buffer, count);</code></pre>
                            </div>
                            <p class="pattern-note fast">✅ <strong>Fast</strong> - Handles ring buffer wrapping automatically, good for most use cases</p>
                        </div>
                        
                        <div class="pattern">
                            <h3>3. Peek/Commit (Zero-Copy)</h3>
                            <div class="code-block">
                                <pre><code class="language-cpp line-numbers">// Reading with peek/commit
const float *ptr1, *ptr2;
size_t size1, size2;
size_t available = in.peek_read(ptr1, size1, ptr2, size2);

// Process ptr1[0..size1] and ptr2[0..size2] directly
process_samples(ptr1, size1);
if (size2 > 0) process_samples(ptr2, size2);
in.commit_read(size1 + size2);

// Writing with peek/commit (variables passed by reference, NOT pointers)
float* write_ptr1, *write_ptr2;
size_t write_size1, write_size2;
size_t writable = out->peek_write(write_ptr1, write_size1, write_ptr2, write_size2);

// Write to both segments
for (size_t i = 0; i < write_size1; ++i) {
    write_ptr1[i] = processed_data[i];
}
for (size_t i = 0; i < write_size2; ++i) {
    write_ptr2[i] = processed_data[write_size1 + i];
}
out->commit_write(write_size1 + write_size2);</code></pre>
                            </div>
                            <p class="pattern-note fastest">⚡ <strong>Fastest</strong> - Zero-copy access. Note: peek_write variables passed by reference, not pointers</p>
                        </div>
                    </div>
                </section>

                <section id="architecture">
                    <h2>Architecture Deep Dive</h2>
                    <p>CLER uses C++17 templates to eliminate all runtime overhead while maintaining type safety and flexibility.</p>
                    
                    <h3>Compile-Time Magic</h3>
                    <div class="code-block">
                        <button class="copy-button" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-cpp line-numbers">template&lt;typename Block, typename... Channels&gt;
struct BlockRunner {
    Block* block;
    std::tuple&lt;Channels*...&gt; outputs;
    
    // Template deduction guide - compiler figures out types automatically
    template&lt;typename... InputChannels&gt;
    BlockRunner(Block* blk, InputChannels*... outs)
        : block(blk), outputs(static_cast&lt;Channels*&gt;(outs)...) {}
};</code></pre>
                    </div>
                    <p class="key-point"><strong>Zero Overhead:</strong> Channel types are deduced at compile time. Minimal runtime type checking, very few virtual function calls, minimal dynamic allocations. The flowgraph code compiles close to what you'd write by hand — often with template optimizations.</p>
                    
                    <h3>AI-Friendly Core (&lt;1000 LOC)</h3>
                    <p>CLER's core is intentionally small and focused:</p>
                    <ul>
                        <li><strong>&lt;1000 lines:</strong> Perfect context window for AI assistance</li>
                        <li><strong>Clear abstractions:</strong> BlockBase, Channel, FlowGraph, Result types</li>
                        <li><strong>Minimal dependencies:</strong> Only standard library, easy to understand</li>
                        <li><strong>Template-heavy:</strong> AI tools excel at understanding and extending template code</li>
                    </ul>
                    <p>This means when you get stuck with complex error messages (CLER's one weakness), any LLM can quickly understand your code and suggest fixes.</p>
                    
                    <h3>Lock-Free Channel Implementation</h3>
                    <p>Based on Dmitry Drogalis's SPSC queue, optimized for DSP workloads:</p>
                    <ul>
                        <li><strong>Cache-aligned:</strong> Prevents false sharing between producer/consumer</li>
                        <li><strong>Memory ordering:</strong> Carefully tuned acquire/release semantics for x86/ARM</li>
                        <li><strong>Configurable sizing:</strong> Stack allocation for embedded, heap for desktop</li>
                        <li><strong>Multiple access patterns:</strong> From simple push/pop to zero-copy peek/commit</li>
                    </ul>
                    
                    <h3>Embedded-First Design</h3>
                    <p>CLER's design choices address real embedded constraints:</p>
                    <ul>
                        <li><strong>No MMU required:</strong> Unlike GNU Radio's double-mapped buffers</li>
                        <li><strong>Predictable timing:</strong> No garbage collection, no unexpected allocations</li>
                        <li><strong>Small memory footprint:</strong> Perfect for microcontrollers</li>
                        <li><strong>Type safety:</strong> Catch connection errors at compile time, not runtime</li>
                    </ul>
                </section>
            </div>
        </div>
    </main>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
    <script>
        function copyCode(button) {
            const codeBlock = button.parentElement.querySelector('code');
            const text = codeBlock.textContent;
            navigator.clipboard.writeText(text).then(() => {
                button.textContent = 'Copied!';
                setTimeout(() => {
                    button.textContent = 'Copy';
                }, 2000);
            });
        }

        // Smooth scrolling for navigation links
        document.querySelectorAll('.learn-nav a').forEach(link => {
            link.addEventListener('click', (e) => {
                e.preventDefault();
                const targetId = link.getAttribute('href').substring(1);
                const targetElement = document.getElementById(targetId);
                if (targetElement) {
                    targetElement.scrollIntoView({ behavior: 'smooth' });
                }
            });
        });

        // Mobile navigation toggle
        document.addEventListener('DOMContentLoaded', function() {
            const toggleBtn = document.querySelector('.nav-toggle');
            const sidebar = document.querySelector('.sidebar');
            const learnNav = document.querySelector('.learn-nav');
            
            if (toggleBtn && sidebar && learnNav) {
                toggleBtn.addEventListener('click', function() {
                    const isOpen = learnNav.classList.toggle('open');
                    sidebar.classList.toggle('open');
                    toggleBtn.setAttribute('aria-expanded', isOpen);
                });
            }
            
            // Auto-close nav on link click (mobile only)
            document.querySelectorAll('.learn-nav a').forEach(link => {
                link.addEventListener('click', () => {
                    if (window.innerWidth <= 768) {
                        sidebar.classList.remove('open');
                        learnNav.classList.remove('open');
                        if (toggleBtn) {
                            toggleBtn.setAttribute('aria-expanded', 'false');
                        }
                    }
                });
            });
        });
    </script>
</body>
</html>